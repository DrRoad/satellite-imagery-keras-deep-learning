{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import json\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score\n",
    "\n",
    "from utils.f2thresholdfinder import *\n",
    "from utils.loaderjpg import *\n",
    "from utils.generator import *\n",
    "from utils.custommetrics import *\n",
    "from utils.visualization import *\n",
    "from utils.predictorjpg import *\n",
    "from utils.file import *\n",
    "\n",
    "from pretrained.vgg16 import *\n",
    "from pretrained.vgg19 import *\n",
    "from pretrained.resnet50 import *\n",
    "from pretrained.densenet121 import *\n",
    "from pretrained.custommodels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading configurations from config file: cfg/tune_vgg19_hack.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:10: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: vgg19\n",
      "number of frozen layers: 13\n",
      "[0.0001, 1e-05]\n",
      "[5, 3]\n",
      "batch size: 16\n"
     ]
    }
   ],
   "source": [
    "# command line args processing \"python tuningfurther.py cfg/3.cfg\"\n",
    "config_file = sys.argv[1]\n",
    "\n",
    "print('reading configurations from config file: {}'.format(config_file))\n",
    "\n",
    "settings = configparser.ConfigParser()\n",
    "settings.read(config_file)\n",
    "data_dir = settings.get('data', 'data_dir')\n",
    "\n",
    "rescaled_dim = 224\n",
    "\n",
    "model_name = settings.get('model', 'name')\n",
    "print('model: {}'.format(model_name))\n",
    "\n",
    "pretrained_model_file = None\n",
    "model_weights_file = None\n",
    "\n",
    "#pretrained_model_file = 'D:/Downloads/amazon/bottleneck/resnet50/frozen164_20170703-204725.h5'\n",
    "if settings.has_option('model', 'source'):\n",
    "    pretrained_model_file = settings.get('model', 'source')\n",
    "    print('source model file: {}'.format(pretrained_model_file))\n",
    "elif settings.has_option('model', 'weights'):\n",
    "    model_weights_file = settings.get('model', 'weights')\n",
    "    print('model weights file: {}'.format(model_weights_file))\n",
    "#else:\n",
    "#    raise ValueError('Error: config file must have model file path or model weights file path')\n",
    "    \n",
    "frozen_layers = settings.getint('model', 'frozen_layers')\n",
    "print('number of frozen layers: {}'.format(frozen_layers))\n",
    "\n",
    "learning_rate_schedule = json.loads(settings.get('model', 'learning_rate_schedule'))\n",
    "print(learning_rate_schedule)\n",
    "max_epoch_per_learning_rate = json.loads(settings.get('model', 'max_epoch_per_learning_rate'))\n",
    "print(max_epoch_per_learning_rate)\n",
    "\n",
    "batch_size = settings.getint('model', 'batch_size') \n",
    "print('batch size: {}'.format(batch_size))\n",
    "#batch_size = 64\n",
    "\n",
    "file_uuid = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "verbose_level = 0\n",
    "\n",
    "labels = ['slash_burn', 'clear', 'blooming', 'primary', 'cloudy', 'conventional_mine', 'water', 'haze', 'cultivation', 'partly_cloudy', 'artisinal_mine', 'habitation', 'bare_ground', 'blow_down', 'agriculture', 'road', 'selective_logging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479L, 224L, 224L, 3L)\n",
      "(40479L, 17L)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(data_dir + 'train_v2.csv')\n",
    "x_train, y_train = load_training_set(df_train, rescaled_dim)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_samples = x_train.shape[0]\n",
    "split = int(number_of_samples * 0.90)\n",
    "                     \n",
    "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]\n",
    "\n",
    "number_validations = number_of_samples - split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# early stopping prevents overfitting on training data\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=1, min_delta=0, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_normalization = image_normalization_func(model_name)\n",
    "\n",
    "train_datagen = BottleNeckImgGenerator(normalization=img_normalization)\n",
    "train_gen = train_datagen.trainGen(x_train, y_train, batch_size)\n",
    "valid_datagen = BottleNeckImgGenerator(normalization=img_normalization)\n",
    "valid_gen = valid_datagen.validationGen(x_valid, y_valid, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-698e7f334e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;31m# TODO uncomment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[1;31m#model = custom_top_model(model_name, num_classes=17, num_frozen_layers=frozen_layers)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg19_model_custom_top_hack2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[1;31m# Load full model file or weight-only file. Addresses bug with Keras load_model for models with custom layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\kaggle\\amazon\\pretrained\\vgg19.py\u001b[0m in \u001b[0;36mvgg19_model_custom_top_hack2\u001b[0;34m(channel, num_classes)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mcustom_fc_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D:/Downloads/amazon/bottleneck/vgg19/bottleneck_fc_model_val_loss_0122.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mtop_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_fc_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[1;31m# # add custom layers as determined by experiments to guess best architecture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    331\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[1;31m# This will call layer.build() if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[1;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[1;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[1;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0moutput_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[1;31m# TODO: try to auto-infer shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\models.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input, mask)\u001b[0m\n\u001b[1;32m   2245\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2248\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\engine\\topology.pyc\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m   2418\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m                             \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_shape_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m                             \u001b[0muses_learning_phase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\layers\\core.pyc\u001b[0m in \u001b[0;36mget_output_shape_for\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[1;32massert\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m         \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0moutput_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# previously top classfier trained to val_loss = 0.105\n",
    "# model = load_model('D:/Downloads/amazon/bottleneck/resnet50/frozen175_20170703-110325.h5')\n",
    "\n",
    "if model_name == 'vgg19':\n",
    "    model = custom_top_model(model_name, num_classes=17, num_frozen_layers=frozen_layers)\n",
    "else:\n",
    "    # Load full model file or weight-only file. Addresses bug with Keras load_model for models with custom layers.\n",
    "    if pretrained_model_file is not None:\n",
    "        model = load_model(pretrained_model_file)\n",
    "        model = freeze_layers(model, num_frozen_layers=frozen_layers)\n",
    "    else:\n",
    "        model = custom_top_model(model_name, num_classes=17, num_frozen_layers=frozen_layers)\n",
    "        model.load_weights(model_weights_file)\n",
    "\n",
    "print(model.summary())\n",
    "# check trainability of all layers\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable if hasattr(layer, 'trainable') else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filepath = data_dir + 'bottleneck/{}/frozen{}_{}.h5'.format(model_name, frozen_layers, file_uuid)\n",
    "# save only the best model, not the latest epoch model.\n",
    "model_checkpoint = ModelCheckpoint(model_filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "\n",
    "# also save the weights because Keras raises error in load_model when model contains custom layers\n",
    "weights_filepath = data_dir + 'bottleneck/{}/frozen{}_{}_weights_only.h5'.format(model_name, frozen_layers, file_uuid)\n",
    "weights_checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_start_time = datetime.now()\n",
    "\n",
    "history = {}\n",
    "f2_history = []\n",
    "\n",
    "num_samples_per_epoch = x_train.shape[0]\n",
    "\n",
    "for learn_rate, epochs in zip(learning_rate_schedule, max_epoch_per_learning_rate):\n",
    "    print('learning rate :{}'.format(learn_rate))\n",
    "    model.optimizer.lr.set_value(learn_rate)\n",
    "    \n",
    "    tmp_history = model.fit_generator(train_gen,\n",
    "                        samples_per_epoch=num_samples_per_epoch,\n",
    "                        nb_epoch=epochs,\n",
    "                        validation_data=valid_gen,\n",
    "                        nb_val_samples=number_validations,              \n",
    "                        verbose=verbose_level,\n",
    "                        callbacks=[early_stop, model_checkpoint, weights_checkpoint])\n",
    "    \n",
    "    for k, v in tmp_history.history.iteritems():\n",
    "        history.setdefault(k, []).extend(v)\n",
    "\n",
    "time_spent_trianing = datetime.now() - training_start_time\n",
    "print('{} model training complete. Time taken: {}'.format(model_name, time_spent_trianing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# warning: load_model does not work for nested models such as our custom VGG19\n",
    "# load your best model before making any final predictions\n",
    "\n",
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "\n",
    "if pretrained_model_file is not None:\n",
    "    print('loading model file: {}'.format(model_filepath))\n",
    "    model = load_model(model_filepath)\n",
    "else:\n",
    "    print('loading model weights file: {}'.format(weights_filepath))\n",
    "    model = custom_top_model(model_name, num_classes=17, num_frozen_layers=frozen_layers)\n",
    "    model.load_weights(weights_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_datagen = BottleNeckImgGenerator(normalization=img_normalization)\n",
    "\n",
    "y_predictions, optimized_thresholds = predict_with_optimal_thresholds(x_valid, y_valid, valid_datagen, model)\n",
    "\n",
    "# save for use in ensembling weight optimization!\n",
    "np.save(data_dir + '/temp/{}_{}_valid_set_predictions'.format(model_name, file_uuid), y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold_df = pd.DataFrame({'label':labels, \n",
    "                             'optimized_threshold':optimized_thresholds})\n",
    "print(threshold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision_l, recall_l, f2_score_l = calculate_stats_for_prediction(y_valid, y_predictions)\n",
    "\n",
    "prediction_stats_df = pd.DataFrame({\n",
    "    'label': labels, \n",
    "    'true_sum': np.sum(y_valid, axis=0),\n",
    "    'predict_sum': np.sum(y_predictions, axis=0),\n",
    "    'f2': f2_score_l,\n",
    "    'recall': recall_l,\n",
    "    'precision': precision_l\n",
    "})\n",
    "\n",
    "# reordering the columns for easier reading\n",
    "prediction_stats_df = prediction_stats_df[['label', 'f2', 'recall', 'precision', 'true_sum', 'predict_sum']]\n",
    "print(prediction_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figures_dir = 'figures/{}'.format(model_name)\n",
    "makedirs(figures_dir)\n",
    "\n",
    "plot_file_path = figures_dir + '/stats_frozen{}_{}.png'.format(frozen_layers, file_uuid)\n",
    "trainHistoryPlot(plot_file_path, history, f2_history, prediction_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_submission_filepath = data_dir + 'sample_submission_v2.csv'\n",
    "\n",
    "real_submission_filepath = data_dir + 'my_submissions/submission_{}_{}.csv'.format(model_name, file_uuid)\n",
    "\n",
    "img_normalization = image_normalization_func(model_name)\n",
    "test_datagen = BottleNeckImgGenerator(normalization=img_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_submission(model,\n",
    "                optimized_thresholds,\n",
    "                rescaled_dim, \n",
    "                labels,\n",
    "                sample_submission_filepath,\n",
    "                real_submission_filepath,\n",
    "                test_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
