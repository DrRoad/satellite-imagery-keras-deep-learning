reading configurations from config file: cfg/tune_vgg16_2.cfg
model: vgg16
source model file: D:/Downloads/amazon/bottleneck/vgg16/frozen17_20170704-145556.h5
number of frozen layers: 16
[2e-05, 4e-06]
[100, 10]
batch size: 64
(40479L, 224L, 224L, 3L)
(40479L, 17L)
(0, u'input_1', False)
(1, u'block1_conv1', False)
(2, u'block1_conv2', False)
(3, u'block1_pool', False)
(4, u'block2_conv1', False)
(5, u'block2_conv2', False)
(6, u'block2_pool', False)
(7, u'block3_conv1', False)
(8, u'block3_conv2', False)
(9, u'block3_conv3', False)
(10, u'block3_pool', False)
(11, u'block4_conv1', False)
(12, u'block4_conv2', False)
(13, u'block4_conv3', False)
(14, u'block4_pool', False)
(15, u'block5_conv1', False)
(16, u'block5_conv2', True)
(17, u'block5_conv3', True)
(18, u'block5_pool', True)
(19, u'flatten_1', True)
(20, u'dense_1', True)
(21, u'dropout_1', True)
(22, u'dense_2', True)
(23, u'dropout_2', True)
(24, u'dense_3', True)
learning rate :2e-05
Epoch 00000: val_loss improved from inf to 0.10429, saving model to D:/Downloads/amazon/bottleneck/vgg16/frozen16_20170704-171125.h5
Epoch 00001: val_loss did not improve
Epoch 00002: val_loss did not improve
learning rate :4e-06
Epoch 00000: val_loss did not improve
Epoch 00001: val_loss did not improve
