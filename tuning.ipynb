{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1060 6GB (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score\n",
    "\n",
    "from utils.f2thresholdfinder import *\n",
    "from utils.loaderjpg import *\n",
    "from utils.generator import *\n",
    "from utils.custommetrics import *\n",
    "from utils.visualization import *\n",
    "from utils.predictorjpg import *\n",
    "from utils.file import *\n",
    "\n",
    "from pretrained.vgg16 import *\n",
    "from pretrained.vgg19 import *\n",
    "from pretrained.resnet50 import *\n",
    "from pretrained.densenet121 import *\n",
    "from pretrained.custommodels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading configurations from config file: cfg/default.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n"
     ]
    }
   ],
   "source": [
    "config_file = 'cfg/default.cfg'\n",
    "\n",
    "print('reading configurations from config file: {}'.format(config_file))\n",
    "\n",
    "settings = configparser.ConfigParser()\n",
    "settings.read(config_file)\n",
    "data_dir = settings.get('data', 'data_dir')\n",
    "\n",
    "rescaled_dim = 224\n",
    "\n",
    "# model_name = 'vgg16'\n",
    "model_name = 'vgg19'\n",
    "# model_name = 'resnet50'\n",
    "# model_name = 'densenet121'\n",
    "\n",
    "# train top layers only\n",
    "top_layer_index_dict = {\n",
    "    'vgg16': 19,\n",
    "    'vgg19': 38,\n",
    "    'resnet50': 175,\n",
    "    'densenet121': 607\n",
    "}\n",
    "\n",
    "train_top_classifer = True\n",
    "\n",
    "file_uuid = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "verbose_level = 0\n",
    "\n",
    "labels = ['slash_burn', 'clear', 'blooming', 'primary', 'cloudy', 'conventional_mine', 'water', 'haze', 'cultivation', 'partly_cloudy', 'artisinal_mine', 'habitation', 'bare_ground', 'blow_down', 'agriculture', 'road', 'selective_logging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frozen_layers = top_layer_index_dict[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'zeropadding2d_1', False)\n",
      "(1, 'convolution2d_1', False)\n",
      "(2, 'zeropadding2d_2', False)\n",
      "(3, 'convolution2d_2', False)\n",
      "(4, 'maxpooling2d_1', False)\n",
      "(5, 'zeropadding2d_3', False)\n",
      "(6, 'convolution2d_3', False)\n",
      "(7, 'zeropadding2d_4', False)\n",
      "(8, 'convolution2d_4', False)\n",
      "(9, 'maxpooling2d_2', False)\n",
      "(10, 'zeropadding2d_5', False)\n",
      "(11, 'convolution2d_5', False)\n",
      "(12, 'zeropadding2d_6', False)\n",
      "(13, 'convolution2d_6', False)\n",
      "(14, 'zeropadding2d_7', False)\n",
      "(15, 'convolution2d_7', False)\n",
      "(16, 'zeropadding2d_8', False)\n",
      "(17, 'convolution2d_8', False)\n",
      "(18, 'maxpooling2d_3', False)\n",
      "(19, 'zeropadding2d_9', False)\n",
      "(20, 'convolution2d_9', False)\n",
      "(21, 'zeropadding2d_10', False)\n",
      "(22, 'convolution2d_10', False)\n",
      "(23, 'zeropadding2d_11', False)\n",
      "(24, 'convolution2d_11', False)\n",
      "(25, 'zeropadding2d_12', False)\n",
      "(26, 'convolution2d_12', False)\n",
      "(27, 'maxpooling2d_4', False)\n",
      "(28, 'zeropadding2d_13', False)\n",
      "(29, 'convolution2d_13', False)\n",
      "(30, 'zeropadding2d_14', False)\n",
      "(31, 'convolution2d_14', False)\n",
      "(32, 'zeropadding2d_15', False)\n",
      "(33, 'convolution2d_15', False)\n",
      "(34, 'zeropadding2d_16', False)\n",
      "(35, 'convolution2d_16', False)\n",
      "(36, 'maxpooling2d_5', False)\n",
      "(37, 'flatten_1', False)\n",
      "(38, 'dense_4', True)\n",
      "(39, 'dropout_3', True)\n",
      "(40, 'dense_5', True)\n",
      "(41, 'dropout_4', True)\n",
      "(42, 'dense_6', True)\n"
     ]
    }
   ],
   "source": [
    "model = custom_top_model(model_name, num_classes=17, num_frozen_layers=frozen_layers)\n",
    "\n",
    "#print(model.summary())\n",
    "# check trainability of all layers\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable if hasattr(layer, 'trainable') else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479L, 224L, 224L, 3L)\n",
      "(40479L, 17L)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(data_dir + 'train_v2.csv')\n",
    "x_train, y_train = load_training_set(df_train, rescaled_dim)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_samples = x_train.shape[0]\n",
    "split = int(number_of_samples * 0.90)\n",
    "                     \n",
    "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]\n",
    "\n",
    "number_validations = number_of_samples - split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_1 (ZeroPadding2D)  (None, 3, 226, 226)   0           zeropadding2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 224, 224)  1792        zeropadding2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_2 (ZeroPadding2D)  (None, 64, 226, 226)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 64, 224, 224)  36928       zeropadding2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 112, 112)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_3 (ZeroPadding2D)  (None, 64, 114, 114)  0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 112, 112) 73856       zeropadding2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_4 (ZeroPadding2D)  (None, 128, 114, 114) 0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 112, 112) 147584      zeropadding2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 56, 56)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 128, 58, 58)   0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 56, 56)   295168      zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 256, 58, 58)   0           convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 256, 56, 56)   590080      zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 28, 28)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 256, 30, 30)   0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 512, 28, 28)   1180160     zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 512, 30, 30)   0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 512, 28, 28)   2359808     zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 14, 14)   0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_13 (ZeroPadding2D) (None, 512, 16, 16)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_14 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_15 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_16 (ZeroPadding2D) (None, 512, 16, 16)   0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 512, 14, 14)   2359808     zeropadding2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 7, 7)     0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 2048)          2050048     dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 2048)          0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1024)          2098176     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 1024)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 17)            17425       dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 24,190,033\n",
      "Trainable params: 4,165,649\n",
      "Non-trainable params: 20,024,384\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# early stopping prevents overfitting on training data\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=1, min_delta=0, verbose=0, mode='auto')\n",
    "\n",
    "model_filepath = data_dir + 'bottleneck/{}/frozen{}_{}.h5'.format(model_name, frozen_layers, file_uuid)\n",
    "# save only the best model, not the latest epoch model.\n",
    "model_checkpoint = ModelCheckpoint(model_filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "\n",
    "# also save the weights because Keras raises error in load_model when model contains custom layers\n",
    "weights_filepath = data_dir + 'bottleneck/{}/frozen{}_{}_weights_only.h5'.format(model_name, frozen_layers, file_uuid)\n",
    "weights_checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# models with more trainable params require a smaller batch size to fit into the GPU memory of my 1060.\n",
    "if model_name == 'densenet121':\n",
    "    batch_size = 32\n",
    "elif model_name == 'vgg19':\n",
    "    batch_size = 16\n",
    "\n",
    "img_normalization = image_normalization_func(model_name)\n",
    "\n",
    "train_datagen = BottleNeckImgGenerator(normalization=img_normalization)\n",
    "train_gen = train_datagen.trainGen(x_train, y_train, batch_size)\n",
    "valid_datagen = BottleNeckImgGenerator(normalization=img_normalization)\n",
    "valid_gen = valid_datagen.validationGen(x_valid, y_valid, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate :0.0001\n"
     ]
    },
    {
     "ename": "GpuArrayException",
     "evalue": "out of memory\nApply node that caused the error: GpuAllocEmpty{dtype='float32', context_name=None}(Assert{msg='The convolution would produce an invalid shape (dim[0] < 0).'}.0, Assert{msg='The convolution would produce an invalid shape (dim[1] < 0).'}.0, Assert{msg='The convolution would produce an invalid shape (dim[2] <= 0).'}.0, Assert{msg='The convolution would produce an invalid shape (dim[3] <= 0).'}.0)\nToposort index: 299\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), (), ()]\nInputs strides: [(), (), (), ()]\nInputs values: [array(16L, dtype=int64), array(64L, dtype=int64), array(224L, dtype=int64), array(224L, dtype=int64)]\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty{dtype='float32', context_name=None}.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGpuArrayException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2e42bbdc692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumber_validations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose_level\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                         callbacks=[early_stop, model_checkpoint, weights_checkpoint])\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\engine\\training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\keras\\keras\\backend\\theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\theano\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\theano\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Me\\Anaconda2\\lib\\site-packages\\theano\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpygpu\\gpuarray.pyx\u001b[0m in \u001b[0;36mpygpu.gpuarray.pygpu_empty (pygpu/gpuarray.c:9764)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpygpu\\gpuarray.pyx\u001b[0m in \u001b[0;36mpygpu.gpuarray.array_empty (pygpu/gpuarray.c:5616)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGpuArrayException\u001b[0m: out of memory\nApply node that caused the error: GpuAllocEmpty{dtype='float32', context_name=None}(Assert{msg='The convolution would produce an invalid shape (dim[0] < 0).'}.0, Assert{msg='The convolution would produce an invalid shape (dim[1] < 0).'}.0, Assert{msg='The convolution would produce an invalid shape (dim[2] <= 0).'}.0, Assert{msg='The convolution would produce an invalid shape (dim[3] <= 0).'}.0)\nToposort index: 299\nInputs types: [TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar)]\nInputs shapes: [(), (), (), ()]\nInputs strides: [(), (), (), ()]\nInputs values: [array(16L, dtype=int64), array(64L, dtype=int64), array(224L, dtype=int64), array(224L, dtype=int64)]\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty{dtype='float32', context_name=None}.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "history = {}\n",
    "f2_history = []\n",
    "\n",
    "learning_rate_schedule = [0.0001, 0.00005]  # starting at 0.001 does not yield good val_loss. \n",
    "max_epoch_per_learning_rate = [70, 10]\n",
    "\n",
    "# using Adam for top layer.\n",
    "if model_name == 'densenet121':\n",
    "    learning_rate_schedule = [0.001, 0.0002]\n",
    "    max_epoch_per_learning_rate = [60, 10]\n",
    "\n",
    "if model_name == 'vgg19':\n",
    "    learning_rate_schedule = [0.01, 0.001]\n",
    "    max_epoch_per_learning_rate = [10, 10]\n",
    "\n",
    "if train_top_classifer:\n",
    "    training_start_time = datetime.now()\n",
    "\n",
    "    num_samples_per_epoch = x_train.shape[0]\n",
    "    \n",
    "    for learn_rate, epochs in zip(learning_rate_schedule, max_epoch_per_learning_rate):\n",
    "        print('learning rate :{}'.format(learn_rate))\n",
    "        model.optimizer.lr.set_value(learn_rate)\n",
    "        \n",
    "        tmp_history = model.fit_generator(train_gen,\n",
    "                        samples_per_epoch=num_samples_per_epoch,\n",
    "                        nb_epoch=epochs,\n",
    "                        validation_data=valid_gen,\n",
    "                        nb_val_samples=number_validations,              \n",
    "                        verbose=verbose_level,\n",
    "                        callbacks=[early_stop, weights_checkpoint]) # model_checkpoint\n",
    "    \n",
    "        for k, v in tmp_history.history.iteritems():\n",
    "            history.setdefault(k, []).extend(v)\n",
    "\n",
    "    time_spent_trianing = datetime.now() - training_start_time\n",
    "    print('top classifier layers training complete. Time taken: {}'.format(time_spent_trianing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #TODO put this in a utils script\n",
    "# def normalize_images(images):\n",
    "#     # int8 to float16, subtract mean, transpose\n",
    "#     x_result = images.astype(np.float16)\n",
    "#     subtract_mean(x_result)\n",
    "#     x_result = x_result.transpose(0,3,1,2) # theano expects channels come before dims\n",
    "#     return x_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if train_top_classifer:\n",
    "    valid_datagen = BottleNeckImgGenerator(normalization=img_normalization)\n",
    "    valid_gen = valid_datagen.validationGen(x_valid, y_valid, batch_size)\n",
    "    \n",
    "    p_valid = model.predict_generator(valid_gen, x_valid.shape[0])\n",
    "    y_predictions = (np.array(p_valid) > 0.2).astype(int)\n",
    "\n",
    "    precision_s = precision_score(y_valid, y_predictions, average='samples')\n",
    "    print('>>>> Overall precision score over validation set ' , precision_s)\n",
    "\n",
    "    recall_s = recall_score(y_valid, y_predictions, average='samples')\n",
    "    print('>>>> Overall recall score over validation set ' , recall_s)\n",
    "\n",
    "    f2_score = fbeta_score(y_valid, y_predictions, beta=2, average='samples')\n",
    "    print('>>>> Overall F2 score over validation set ' , f2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figures_dir = 'figures/{}'.format(model_name)\n",
    "makedirs(figures_dir)\n",
    "\n",
    "plot_file_path = figures_dir + '/stats_frozen{}_{}.png'.format(frozen_layers, file_uuid)\n",
    "trainHistoryPlot(plot_file_path, history, [], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
