{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1060 6GB (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score\n",
    "\n",
    "from utils.f2thresholdfinder import *\n",
    "from utils.loaderjpg import *\n",
    "from utils.generator import *\n",
    "from utils.custommetrics import *\n",
    "from utils.visualization import *\n",
    "from utils.predictorjpg import *\n",
    "from utils.file import *\n",
    "\n",
    "from pretrained.vgg16 import *\n",
    "from pretrained.resnet50 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading configurations from config file: cfg/default.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Me\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:6: DeprecationWarning: You passed a bytestring as `filenames`. This will not work on Python 3. Use `cp.read_file()` or switch to using Unicode strings across the board.\n"
     ]
    }
   ],
   "source": [
    "config_file = 'cfg/default.cfg'\n",
    "\n",
    "print('reading configurations from config file: {}'.format(config_file))\n",
    "\n",
    "settings = configparser.ConfigParser()\n",
    "settings.read(config_file)\n",
    "data_dir = settings.get('data', 'data_dir')\n",
    "\n",
    "rescaled_dim = 224\n",
    "\n",
    "model_name = 'vgg16'\n",
    "#model_name = 'resnet50'\n",
    "\n",
    "train_top_classifer = True\n",
    "\n",
    "file_uuid = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "verbose_level = 0\n",
    "\n",
    "labels = ['slash_burn', 'clear', 'blooming', 'primary', 'cloudy', 'conventional_mine', 'water', 'haze', 'cultivation', 'partly_cloudy', 'artisinal_mine', 'habitation', 'bare_ground', 'blow_down', 'agriculture', 'road', 'selective_logging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40479L, 224L, 224L, 3L)\n",
      "(40479L, 17L)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(data_dir + 'train_v2.csv')\n",
    "x_train, y_train = load_training_set(df_train, rescaled_dim)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subtract the mean\n",
    "# Reference: https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "# BGR mean values [103.94, 116.78, 123.68] should be subtracted before feeding into the model\n",
    "\n",
    "#x_train[:,:,:,0] -= 104\n",
    "#x_train[:,:,:,1] -= 117\n",
    "#x_train[:,:,:,2] -= 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_samples = x_train.shape[0]\n",
    "split = int(number_of_samples * 0.90)\n",
    "                     \n",
    "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]\n",
    "\n",
    "number_validations = number_of_samples - split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 64, 224, 224)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 64, 224, 224)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 64, 112, 112)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 128, 112, 112) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 128, 112, 112) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 128, 56, 56)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 256, 56, 56)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 256, 28, 28)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 512, 28, 28)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 512, 14, 14)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 512, 14, 14)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 512, 7, 7)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 17)            69649       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,330,193\n",
      "Trainable params: 119,615,505\n",
      "Non-trainable params: 14,714,688\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "(0, 'input_1', False)\n",
      "(1, 'block1_conv1', False)\n",
      "(2, 'block1_conv2', False)\n",
      "(3, 'block1_pool', False)\n",
      "(4, 'block2_conv1', False)\n",
      "(5, 'block2_conv2', False)\n",
      "(6, 'block2_pool', False)\n",
      "(7, 'block3_conv1', False)\n",
      "(8, 'block3_conv2', False)\n",
      "(9, 'block3_conv3', False)\n",
      "(10, 'block3_pool', False)\n",
      "(11, 'block4_conv1', False)\n",
      "(12, 'block4_conv2', False)\n",
      "(13, 'block4_conv3', False)\n",
      "(14, 'block4_pool', False)\n",
      "(15, 'block5_conv1', False)\n",
      "(16, 'block5_conv2', False)\n",
      "(17, 'block5_conv3', False)\n",
      "(18, 'block5_pool', False)\n",
      "(19, 'flatten_1', True)\n",
      "(20, 'dense_1', True)\n",
      "(21, 'dropout_1', True)\n",
      "(22, 'dense_2', True)\n",
      "(23, 'dropout_2', True)\n",
      "(24, 'dense_3', True)\n"
     ]
    }
   ],
   "source": [
    "if model_name == 'vgg16':\n",
    "    frozen_layers = 19 # train top layers only\n",
    "    model = vgg16_model_custom_top(num_classes=17, \n",
    "                                   num_frozen_layers=frozen_layers)\n",
    "elif model_name == 'resnet50':\n",
    "    frozen_layers = 175 # 175 : classifier top layers only\n",
    "    model = resnet50_model_custom_top(num_classes=17, \n",
    "                                      num_frozen_layers=frozen_layers)\n",
    "else:\n",
    "    raise ValueError('Unsupported Model : {}'.format(model_name))\n",
    "\n",
    "print(model.summary())\n",
    "# check trainability of all layers\n",
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable if hasattr(layer, 'trainable') else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 64, 224, 224)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 64, 224, 224)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 64, 112, 112)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 128, 112, 112) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 128, 112, 112) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 128, 56, 56)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 256, 56, 56)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 256, 56, 56)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 256, 28, 28)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 512, 28, 28)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 512, 28, 28)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 512, 14, 14)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 512, 14, 14)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 512, 14, 14)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 512, 7, 7)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          102764544   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4096)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 17)            69649       dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 134,330,193\n",
      "Trainable params: 119,615,505\n",
      "Non-trainable params: 14,714,688\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# early stopping prevents overfitting on training data\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=1, min_delta=0, verbose=0, mode='auto')\n",
    "\n",
    "model_filepath = data_dir + 'bottleneck/{}/frozen{}_{}.h5'.format(model_name, frozen_layers, file_uuid)\n",
    "# save only the best model, not the latest epoch model.\n",
    "checkpoint = ModelCheckpoint(model_filepath, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "custom_gen = CustomImgGenerator()\n",
    "\n",
    "train_datagen = BottleNeckImgGenerator()\n",
    "train_gen = train_datagen.trainGen(x_train, y_train, batch_size)\n",
    "valid_datagen = BottleNeckImgGenerator()\n",
    "valid_gen = valid_datagen.validationGen(x_valid, y_valid, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate :0.0001\n",
      "Epoch 00000: val_loss improved from inf to 0.11933, saving model to D:/Downloads/amazon/bottleneck/vgg16/frozen19_20170704-132538.h5\n",
      "Epoch 00001: val_loss improved from 0.11933 to 0.11524, saving model to D:/Downloads/amazon/bottleneck/vgg16/frozen19_20170704-132538.h5\n",
      "Epoch 00002: val_loss improved from 0.11524 to 0.11293, saving model to D:/Downloads/amazon/bottleneck/vgg16/frozen19_20170704-132538.h5\n",
      "Epoch 00003: val_loss improved from 0.11293 to 0.11057, saving model to D:/Downloads/amazon/bottleneck/vgg16/frozen19_20170704-132538.h5\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "learning rate :5e-05\n",
      "Epoch 00000: val_loss did not improve\n",
      "Epoch 00001: val_loss did not improve\n",
      "Epoch 00002: val_loss did not improve\n",
      "top classifier layers training complete. Time taken: 1:06:43.661000\n"
     ]
    }
   ],
   "source": [
    "history = {}\n",
    "f2_history = []\n",
    "\n",
    "# train the top classifer only from the full model\n",
    "if train_top_classifer:\n",
    "    training_start_time = datetime.now()\n",
    "\n",
    "    learning_rate_schedule = [0.0001, 0.00005]  # starting at 0.001 does not yeild good val_loss. \n",
    "    max_epoch_per_learning_rate = [70, 10]\n",
    "    num_samples_per_epoch = x_train.shape[0]\n",
    "    \n",
    "    for learn_rate, epochs in zip(learning_rate_schedule, max_epoch_per_learning_rate):\n",
    "        print('learning rate :{}'.format(learn_rate))\n",
    "        model.optimizer.lr.set_value(learn_rate)\n",
    "        \n",
    "        tmp_history = model.fit_generator(train_gen,\n",
    "                        samples_per_epoch=num_samples_per_epoch,\n",
    "                        nb_epoch=epochs,\n",
    "                        validation_data=valid_gen,\n",
    "                        nb_val_samples=number_validations,              \n",
    "                        verbose=verbose_level,\n",
    "                        callbacks=[early_stop, checkpoint])\n",
    "    \n",
    "        for k, v in tmp_history.history.iteritems():\n",
    "            history.setdefault(k, []).extend(v)\n",
    "\n",
    "    time_spent_trianing = datetime.now() - training_start_time\n",
    "    print('top classifier layers training complete. Time taken: {}'.format(time_spent_trianing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #TODO put this in a utils script\n",
    "# def normalize_images(images):\n",
    "#     # int8 to float16, subtract mean, transpose\n",
    "#     x_result = images.astype(np.float16)\n",
    "#     subtract_mean(x_result)\n",
    "#     x_result = x_result.transpose(0,3,1,2) # theano expects channels come before dims\n",
    "#     return x_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('>>>> Overall precision score over validation set ', 0.85523911474998426)\n",
      "('>>>> Overall recall score over validation set ', 0.93329833662714101)\n",
      "('>>>> Overall F2 score over validation set ', 0.90642164315693663)\n"
     ]
    }
   ],
   "source": [
    "if train_top_classifer:\n",
    "    valid_datagen = BottleNeckImgGenerator()\n",
    "    valid_gen = valid_datagen.validationGen(x_valid, y_valid, batch_size)\n",
    "    \n",
    "    p_valid = model.predict_generator(valid_gen, x_valid.shape[0])\n",
    "    y_predictions = (np.array(p_valid) > 0.2).astype(int)\n",
    "\n",
    "    precision_s = precision_score(y_valid, y_predictions, average='samples')\n",
    "    print('>>>> Overall precision score over validation set ' , precision_s)\n",
    "\n",
    "    recall_s = recall_score(y_valid, y_predictions, average='samples')\n",
    "    print('>>>> Overall recall score over validation set ' , recall_s)\n",
    "\n",
    "    f2_score = fbeta_score(y_valid, y_predictions, beta=2, average='samples')\n",
    "    print('>>>> Overall F2 score over validation set ' , f2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figures_dir = 'figures/{}'.format(model_name)\n",
    "makedirs(figures_dir)\n",
    "\n",
    "plot_file_path = figures_dir + '/stats_frozen{}_{}.png'.format(frozen_layers, file_uuid)\n",
    "trainHistoryPlot(plot_file_path, history, [], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # unfreeze more layers for second stage training\n",
    "\n",
    "# if train_top_classifer:\n",
    "#     # will loading the best model from Checkpoint improve performance?\n",
    "#     frozen_layers = 164\n",
    "#     model = freeze_layers(model, num_frozen_layers=frozen_layers)\n",
    "\n",
    "#     model_filepath = data_dir + 'bottleneck/{}/frozen{}_{}.h5'.format(model_name, frozen_layers, file_uuid)\n",
    "#     # save only the best model, not the latest epoch model.\n",
    "#     checkpoint = ModelCheckpoint(model_filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "#     # check trainability of all layers\n",
    "#     for i, layer in enumerate(model.layers):\n",
    "#        print(i, layer.name, layer.trainable if hasattr(layer, 'trainable') else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training_start_time = datetime.now()\n",
    "\n",
    "# learning_rate_schedule = [0.001, 0.0002]\n",
    "# max_epoch_per_learning_rate = [100, 100]\n",
    "\n",
    "# history = {}\n",
    "# f2_history = []\n",
    "\n",
    "# num_samples_per_epoch = x_train.shape[0]\n",
    "\n",
    "# for learn_rate, epochs in zip(learning_rate_schedule, max_epoch_per_learning_rate):\n",
    "#     print('learning rate :{}'.format(learn_rate))\n",
    "#     model.optimizer.lr.set_value(learn_rate)\n",
    "    \n",
    "#     tmp_history = model.fit_generator(train_gen,\n",
    "#                         samples_per_epoch=num_samples_per_epoch,\n",
    "#                         nb_epoch=epochs,\n",
    "#                         validation_data=valid_gen,\n",
    "#                         nb_val_samples=number_validations,              \n",
    "#                         verbose=verbose_level,\n",
    "#                         callbacks=[early_stop, checkpoint])\n",
    "    \n",
    "#     for k, v in tmp_history.history.iteritems():\n",
    "#         history.setdefault(k, []).extend(v)\n",
    "\n",
    "# time_spent_trianing = datetime.now() - training_start_time\n",
    "# print('{} model training complete. Time taken: {}'.format(model_name, time_spent_trianing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # load your best model before making any final predictions\n",
    "# import gc\n",
    "# del model\n",
    "# gc.collect()\n",
    "# print('loading model: {}'.format(model_filepath))\n",
    "# model = load_model(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# valid_datagen = BottleNeckImgGenerator()\n",
    "# valid_gen = valid_datagen.validationGen(x_valid, y_valid, batch_size)\n",
    "\n",
    "# p_valid = model.predict_generator(valid_gen, number_validations)\n",
    "\n",
    "# optimized_thresholds = f2_optimized_thresholds(y_valid, p_valid)\n",
    "\n",
    "# y_predictions = (np.array(p_valid) > optimized_thresholds).astype(int)\n",
    "\n",
    "# precision_s = precision_score(y_valid, y_predictions, average='samples')\n",
    "# print('>>>> Overall precision score over validation set ' , precision_s)\n",
    "\n",
    "# recall_s = recall_score(y_valid, y_predictions, average='samples')\n",
    "# print('>>>> Overall recall score over validation set ' , recall_s)\n",
    "\n",
    "# # F2 score, which gives twice the weight to recall\n",
    "# # 'samples' is what the evaluation criteria is for the contest\n",
    "# f2_score = fbeta_score(y_valid, y_predictions, beta=2, average='samples')\n",
    "# print('>>>> Overall F2 score over validation set ' , f2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# threshold_df = pd.DataFrame({'label':labels, \n",
    "#                              'optimized_threshold':optimized_thresholds})\n",
    "# print(threshold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# precision_l, recall_l, f2_score_l = calculate_stats_for_prediction(y_valid, y_predictions)\n",
    "\n",
    "# prediction_stats_df = pd.DataFrame({\n",
    "#     'label': labels, \n",
    "#     'true_sum': np.sum(y_valid, axis=0),\n",
    "#     'predict_sum': np.sum(y_predictions, axis=0),\n",
    "#     'f2': f2_score_l,\n",
    "#     'recall': recall_l,\n",
    "#     'precision': precision_l\n",
    "# })\n",
    "\n",
    "# # reordering the columns for easier reading\n",
    "# prediction_stats_df = prediction_stats_df[['label', 'f2', 'recall', 'precision', 'true_sum', 'predict_sum']]\n",
    "# print(prediction_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figures_dir = 'figures/{}'.format(model_name)\n",
    "# makedirs(figures_dir)\n",
    "\n",
    "# plot_file_path = figures_dir + '/stats_frozen{}_{}.png'.format(frozen_layers, file_uuid)\n",
    "# trainHistoryPlot(plot_file_path, history, f2_history, prediction_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sample_submission_filepath = data_dir + 'sample_submission_v2.csv'\n",
    "\n",
    "# real_submission_filepath = data_dir + 'my_submissions/submission_{}_{}.csv'.format(model_name, file_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make_submission(model,\n",
    "#                 optimized_thresholds,\n",
    "#                 rescaled_dim, \n",
    "#                 labels, \n",
    "#                 sample_submission_filepath,\n",
    "#                 real_submission_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
